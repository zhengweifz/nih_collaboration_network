{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Combine publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "study_pub = pd.read_csv(\"../data/study_author_pub.csv\", header=0)\n",
    "comp_pub = pd.read_csv(\"../data/comp_author_pub.csv\", header=0)\n",
    "# create author full names to expand author lists of publications\n",
    "study_pub['author_name'] = study_pub['last_name'].str.capitalize() + ', ' + study_pub['first_name'].str.capitalize() + ' ' +  study_pub['middle_initial'].str.upper()\n",
    "comp_pub['author_name'] = comp_pub['last_name'].str.capitalize() + ', ' + comp_pub['first_name'].str.capitalize() + ' ' +  comp_pub['middle_initial'].str.upper()\n",
    "study_pub['author_name_no_mi'] = study_pub['last_name'].str.capitalize() + ', ' + study_pub['first_name'].str.capitalize() \n",
    "comp_pub['author_name_no_mi'] = comp_pub['last_name'].str.capitalize() + ', ' + comp_pub['first_name'].str.capitalize() \n",
    "study_authors_df = study_pub[['author_name','author_name_no_mi']]\n",
    "comp_authors_df = comp_pub[['author_name','author_name_no_mi']]\n",
    "study_authors_df = study_authors_df.drop_duplicates('author_name')\n",
    "comp_authors_df = comp_authors_df.drop_duplicates('author_name')\n",
    "study_authors = study_authors_df.values[:,0]\n",
    "study_authors_nomi = study_authors_df.values[:,1]\n",
    "comp_authors = comp_authors_df.values[:,0]\n",
    "comp_authors_nomi = comp_authors_df.values[:,1]\n",
    "#combine all publications\n",
    "all_pub = pd.concat([study_pub, comp_pub], axis=0)\n",
    "all_pub = all_pub.drop_duplicates('PMID')\n",
    "temp_df = all_pub[['AUTHOR_LIST','PMID']]\n",
    "temp_df = all_pub[['AUTHOR_LIST','PMID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand the author list column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#expand the author list to a long format\n",
    "vals = temp_df.values\n",
    "numRow, numCol = vals.shape\n",
    "authors = []\n",
    "pmid = []\n",
    "group = []\n",
    "for i in range(numRow):\n",
    "    if vals[i, 0] is not None and vals[i, 1] is not None:\n",
    "        al = vals[i, 0].strip().split(';')\n",
    "        al = [a.strip() for a in al ]\n",
    "        al = [a for a in al if  a != '']\n",
    "        for a in al:\n",
    "            if a in study_authors:\n",
    "                group.append('study')\n",
    "                authors.append(a)\n",
    "            elif a in study_authors_nomi:\n",
    "                group.append('study')\n",
    "                authors.append(str(study_authors[study_authors_nomi==a][0]))\n",
    "            elif a in comp_authors:\n",
    "                group.append('comp')\n",
    "                authors.append(a)\n",
    "            elif a in comp_authors_nomi:\n",
    "                group.append('comp')\n",
    "                authors.append(str(comp_authors[comp_authors_nomi==a][0]))\n",
    "            elif a == 'Nelson, William James':\n",
    "                group.append('study')\n",
    "                authors.append('Nelson, William J')\n",
    "            elif a == 'Macmillan, David W C':\n",
    "                group.append('study')\n",
    "                authors.append('Macmillan, David W')\n",
    "            elif a == 'Pendergast, Ann Marie':\n",
    "                group.append('comp')\n",
    "                authors.append('Pendergast, Ann M')\n",
    "            elif a == 'Au, Jessie L-S':\n",
    "                group.append('comp')\n",
    "                authors.append('Au, Jessie L') \n",
    "            elif a == 'Peterlin, Boris Matija':\n",
    "                group.append('comp')\n",
    "                authors.append('Peterlin, Boris M') \n",
    "            elif a == 'Yan, Shi Du':\n",
    "                group.append('comp')\n",
    "                authors.append('Yan, Shi D')     \n",
    "            else:\n",
    "                group.append('others')\n",
    "                authors.append(a)\n",
    "            pmid.append(vals[i, 1])\n",
    "df_net = pd.DataFrame({'authors': authors, 'pmid': pmid, 'group': group})\n",
    "df_net = df_net[df_net.authors != 'nan']\n",
    "df_net  = df_net.drop_duplicates()\n",
    "df_net.to_csv('../data/net_raw.csv', index=False, header=True)\n",
    "df_net.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('net_raw.csv', header=0)\n",
    "df_other = df[df.group=='others']\n",
    "df_study = df[df.group=='study']\n",
    "df_comp = df[df.group=='comp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter other authors by the number of their publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_by_pub_count(df, numPub):\n",
    "    def get_num_pub(df):\n",
    "        lenG = len(df['pmid'].unique())\n",
    "        if lenG > numPub:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    d = df.groupby(['authors']).filter(get_num_pub)\n",
    "    df = pd.concat([df_study, df_comp, d], axis=0)\n",
    "    df.to_csv('../data/author_has_pub_gt_' + str(numPub) + '_raw.csv', header=True, index=False)\n",
    "    df_node = df[['authors', 'group']]\n",
    "    df_node = df_node.drop_duplicates()\n",
    "    df_node.columns = ['Id', 'Group']\n",
    "    df_node.to_csv('../data/author_has_pub_gt_' + str(numPub) + '_nodes_gephi.csv', header=True, index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_author_other_has_pub_gt_10 = filter_by_pub_count(df_other, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### combine study and comparision groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_study_comb = pd.concat([df_study, df_comp], axis=0)\n",
    "df_study_comb.to_csv('../data/study_comb_raw.csv', header=True, index=False)\n",
    "df_node = df_study_comb[['authors', 'group']]\n",
    "df_node = df_node.drop_duplicates()\n",
    "df_node.columns = ['Id', 'Group']\n",
    "df_node.to_csv('../data/study_comb_nodes_gephi.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### study, comparison, and all groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the whole set of authors\n",
    "df_net = df[['authors', 'pmid']]\n",
    "df_group = df[['authors', 'group']]\n",
    "df_group = df_group.drop_duplicates()\n",
    "df_group.columns = ['Id', 'Group']\n",
    "## study group\n",
    "\n",
    "df_study_gr = df_study[['authors', 'group']]\n",
    "df_study_gr = df_study_gr.drop_duplicates()\n",
    "df_study_gr.columns = ['Id', 'Group']\n",
    "## comp group\n",
    "\n",
    "df_comp_gr = df_comp[['authors', 'group']]\n",
    "df_comp_gr = df_comp_gr.drop_duplicates()\n",
    "df_comp_gr.columns = ['Id', 'Group']\n",
    "df_group.to_csv('../data/all_nodes_gephi.csv', header=True)\n",
    "df_study_gr.to_csv('../data/study_nodes_gephi.csv', header=True)\n",
    "df_comp_gr.to_csv('../data/comp_nodes_gephi.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#unique publications\n",
    "#looping over publications to create edge list\n",
    "activities = all_pub[['PMID','ACTIVITY']]\n",
    "def getEdges(df):\n",
    "    uniq_pub = df.pmid.unique()\n",
    "    edges_list = np.empty((0,2), 'object')\n",
    "    pmids = np.empty(0, np.float64)\n",
    "    for idx, p in enumerate(uniq_pub):\n",
    "        if (idx % 1000) == 0:\n",
    "            print(idx)\n",
    "        df_p = df[df.pmid == p]\n",
    "        a4p = df_p.values[:,0]\n",
    "        len_a = len(a4p)\n",
    "        for i in range(len_a):\n",
    "            if len_a == 1:\n",
    "                num_row = 1\n",
    "                edges = np.empty((num_row, 2), 'object')\n",
    "                edges[:,0] = a4p[i]\n",
    "                edges[:,1] = a4p[i]\n",
    "                edges_list = np.r_[edges_list, edges]\n",
    "                e_ids = np.ones(num_row) * p\n",
    "                pmids = np.r_[pmids, e_ids]\n",
    "            else:\n",
    "                if i == (len_a - 1):\n",
    "                    pass\n",
    "                else:\n",
    "                    num_row = len_a - i - 1\n",
    "                    edges = np.empty((num_row, 2), 'object')\n",
    "                    edges[:,0] = a4p[i]\n",
    "                    edges[:,1] = a4p[i+1::]\n",
    "                    e_ids = np.ones(num_row) * p\n",
    "                    edges_list = np.r_[edges_list, edges]\n",
    "                    pmids = np.r_[pmids, e_ids]\n",
    "    return edges_list, pmids\n",
    "\n",
    "def createGraphCsv(edge_list, pmids, file_name):\n",
    "    df_edges_raws = pd.DataFrame(edge_list, columns=['Source', 'Targe'])\n",
    "    df_edges_pmids = pd.DataFrame(pmids, columns=['pmids'])\n",
    "    df_gephi = pd.concat([df_edges_raws, df_edges_pmids], axis=1);\n",
    "    df_gephi.columns = ['Source', 'Target', 'Label']\n",
    "    ### undirect graph \n",
    "    df_gephi['Type'] = 'Undirected'\n",
    "    pub_attr = all_pub[['PMID', 'PUB_YEAR','COUNTRY']]\n",
    "    df_gephi = df_gephi.merge(pub_attr, left_on='Label', right_on='PMID', how='left')\n",
    "    df_gephi = df_gephi.merge(activities, left_on='Label', right_on='PMID', how='left')\n",
    "    df_gephi = df_gephi[df_gephi.Source != df_gephi.Target]\n",
    "    df_gephi.to_csv(\"../data/\" + file_name + '.csv', index=False, header=True)\n",
    "    return df_gephi\n",
    "\n",
    "def createEdges(df, fileName):\n",
    "   edges, pmids = getEdges(df)\n",
    "   df = createGraphCsv(edges, pmids, fileName) \n",
    "   return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_comp_edges  = createEdges(df_study_comb,  'study_comp_edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_author_other_has_pub_gt_10_edges = createEdges(df_study_comb,  'author_other_has_pub_gt_10_edges')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
