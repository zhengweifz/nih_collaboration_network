{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "study_pub = pd.read_csv(\"../data/study_author_pub.csv\", header=0)\n",
    "comp_pub = pd.read_csv(\"../data/comp_author_pub.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create author full names to expand author lists of publications\n",
    "study_pub['author_name'] = study_pub['last_name'].str.capitalize() + ', ' + study_pub['first_name'].str.capitalize() + ' ' +  study_pub['middle_initial'].str.upper()\n",
    "comp_pub['author_name'] = comp_pub['last_name'].str.capitalize() + ', ' + comp_pub['first_name'].str.capitalize() + ' ' +  comp_pub['middle_initial'].str.upper()\n",
    "study_pub['author_name_no_mi'] = study_pub['last_name'].str.capitalize() + ', ' + study_pub['first_name'].str.capitalize() \n",
    "comp_pub['author_name_no_mi'] = comp_pub['last_name'].str.capitalize() + ', ' + comp_pub['first_name'].str.capitalize() \n",
    "study_authors_df = study_pub[['author_name','author_name_no_mi']]\n",
    "comp_authors_df = comp_pub[['author_name','author_name_no_mi']]\n",
    "study_authors_df = study_authors_df.drop_duplicates('author_name')\n",
    "comp_authors_df = comp_authors_df.drop_duplicates('author_name')\n",
    "study_authors = study_authors_df.values[:,0]\n",
    "study_authors_nomi = study_authors_df.values[:,1]\n",
    "comp_authors = comp_authors_df.values[:,0]\n",
    "comp_authors_nomi = comp_authors_df.values[:,1]\n",
    "#combine all publications\n",
    "all_pub = pd.concat([study_pub, comp_pub], axis=0)\n",
    "all_pub = all_pub.drop_duplicates('PMID')\n",
    "temp_df = all_pub[['AUTHOR_LIST','PMID']]\n",
    "temp_df = all_pub[['AUTHOR_LIST','PMID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#expand the author list to a long format\n",
    "vals = temp_df.values\n",
    "numRow, numCol = vals.shape\n",
    "authors = []\n",
    "pmid = []\n",
    "group = []\n",
    "for i in range(numRow):\n",
    "    if vals[i, 0] is not None and vals[i, 1] is not None:\n",
    "        al = vals[i, 0].strip().split(';')\n",
    "        al = [a.strip() for a in al ]\n",
    "        al = [a for a in al if  a != '']\n",
    "        for a in al:\n",
    "            if a in study_authors:\n",
    "                group.append('study')\n",
    "                authors.append(a)\n",
    "            elif a in study_authors_nomi:\n",
    "                group.append('study')\n",
    "                authors.append(str(study_authors[study_authors_nomi==a][0]))\n",
    "            elif a in comp_authors:\n",
    "                group.append('comp')\n",
    "                authors.append(a)\n",
    "            elif a in comp_authors_nomi:\n",
    "                group.append('comp')\n",
    "                authors.append(str(comp_authors[comp_authors_nomi==a][0]))\n",
    "            elif a == 'Nelson, William James':\n",
    "                group.append('study')\n",
    "                authors.append('Nelson, William J')\n",
    "            elif a == 'Macmillan, David W C':\n",
    "                group.append('study')\n",
    "                authors.append('Macmillan, David W')\n",
    "            elif a == 'Pendergast, Ann Marie':\n",
    "                group.append('comp')\n",
    "                authors.append('Pendergast, Ann M')\n",
    "            elif a == 'Au, Jessie L-S':\n",
    "                group.append('comp')\n",
    "                authors.append('Au, Jessie L') \n",
    "            elif a == 'Peterlin, Boris Matija':\n",
    "                group.append('comp')\n",
    "                authors.append('Peterlin, Boris M') \n",
    "            elif a == 'Yan, Shi Du':\n",
    "                group.append('comp')\n",
    "                authors.append('Yan, Shi D')     \n",
    "            else:\n",
    "                group.append('others')\n",
    "                authors.append(a)\n",
    "            pmid.append(vals[i, 1])\n",
    "df_net = pd.DataFrame({'authors': authors, 'pmid': pmid, 'group': group})\n",
    "df_net = df_net[df_net.authors != 'nan']\n",
    "df_net.to_csv('../data/net_raw.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382676, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_net.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the whole set of authors\n",
    "df = pd.read_csv('net_raw.csv', header=0)\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv('../data/net_raw.csv', index=False, header=True)\n",
    "df_net = df[['authors', 'pmid']]\n",
    "df_group = df[['authors', 'group']]\n",
    "df_group = df_group.drop_duplicates()\n",
    "df_group.columns = ['Id', 'Group']\n",
    "## study group\n",
    "df_study = df[df.group=='study']\n",
    "df_study_gr = df_study[['authors', 'group']]\n",
    "df_study_gr = df_study_gr.drop_duplicates()\n",
    "df_study_gr.columns = ['Id', 'Group']\n",
    "## comp group\n",
    "df_comp = df[df.group=='comp']\n",
    "df_comp_gr = df_comp[['authors', 'group']]\n",
    "df_comp_gr = df_comp_gr.drop_duplicates()\n",
    "df_comp_gr.columns = ['Id', 'Group']\n",
    "df_group.to_csv('../data/all_nodes_gephi.csv', header=True)\n",
    "df_study_gr.to_csv('../data/study_nodes_gephi.csv', header=True)\n",
    "df_comp_gr.to_csv('../data/comp_nodes_gephi.csv', header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#unique publications\n",
    "#looping over publications to create edge list\n",
    "def getEdges(df):\n",
    "    uniq_pub = df.pmid.unique()\n",
    "    edges_list = np.empty((0,2), 'object')\n",
    "    pmids = np.empty(0, np.float64)\n",
    "    for idx, p in enumerate(uniq_pub):\n",
    "        if (idx % 1000) == 0:\n",
    "            print(idx)\n",
    "        df_p = df[df.pmid == p]\n",
    "        a4p = df_p.values[:,0]\n",
    "        len_a = len(a4p)\n",
    "        for i in range(len_a):\n",
    "            if len_a == 1:\n",
    "                edges[:,0] = a4p[i]\n",
    "                edges[:,1] = a4p[i]\n",
    "                edges_list = np.r_[edges_list, edges]\n",
    "                num_row = 1\n",
    "                e_ids = np.ones(num_row) * p\n",
    "                pmids = np.r_[pmids, e_ids]\n",
    "            else:\n",
    "                if i == (len_a - 1):\n",
    "                    pass\n",
    "                else:\n",
    "                    num_row = len_a - i - 1\n",
    "                    edges = np.empty((num_row, 2), 'object')\n",
    "                    edges[:,0] = a4p[i]\n",
    "                    edges[:,1] = a4p[i+1::]\n",
    "                    e_ids = np.ones(num_row) * p\n",
    "                    edges_list = np.r_[edges_list, edges]\n",
    "                    pmids = np.r_[pmids, e_ids]\n",
    "    return edges_list, pmids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "study_edges, study_pmid = getEdges(df_study)\n",
    "comp_edges, comp_pmid = getEdges(df_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#full network take 3-4 hours to run\n",
    "all_edges, all_pmid = getEdges(df_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Kellogg, Douglas R', 'Sullivan, William T'],\n",
       "       ['Stivers, James T', 'Cole, Philip A'],\n",
       "       ['Stivers, James T', 'Greenberg, Marc M'],\n",
       "       ..., \n",
       "       ['Glick, Benjamin S', 'Rothman, James E'],\n",
       "       ['Linstedt, Adam D', 'Rothman, James E'],\n",
       "       ['Cane, David E', 'Puglisi, Joseph D']], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createGraphCsv(edge_list, pmids, file_name):\n",
    "    df_edges_raws = pd.DataFrame(edge_list, columns=['Source', 'Targe'])\n",
    "    df_edges_pmids = pd.DataFrame(pmids, columns=['pmids'])\n",
    "    df_gephi = pd.concat([df_edges_raws, df_edges_pmids], axis=1);\n",
    "    df_gephi.columns = ['Source', 'Target', 'Label']\n",
    "    ### undirect graph \n",
    "    df_gephi['Type'] = 'Undirected'\n",
    "    pub_attr = all_pub[['PMID', 'PUB_YEAR','COUNTRY']]\n",
    "    df_gephi = df_gephi.merge(pub_attr, left_on='Label', right_on='PMID', how='left')\n",
    "    df_gephi.drop(['PMID'], axis=1, inplace=True)\n",
    "    df_gephi.to_csv(\"../data/\" + file_name + '.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "createGraphCsv(study_edges, study_pmid, 'study_edges')\n",
    "createGraphCsv(comp_edges, comp_pmid, 'comp_edges')\n",
    "createGraphCsv(all_edges, all_pmid, 'all_edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add Funding Activity R01...\n",
    "study_edges = pd.read_csv('../data/study_edges.csv', header=0)\n",
    "activities = all_pub[['PMID','ACTIVITY']]\n",
    "study_edges = study_edges.merge(activities, left_on='Label', right_on='PMID', how='left')\n",
    "study_edges.to_csv('../data/study_edges.csv', index=False, header=True)\n",
    "comp_edges = pd.read_csv('../data/comp_edges.csv', header=0)\n",
    "comp_edges = comp_edges.merge(activities, left_on='Label', right_on='PMID', how='left')\n",
    "comp_edges.to_csv('../data/comp_edges.csv', index=False, header=True)\n",
    "all_edges = pd.read_csv('../data/all_edges.csv', header=0)\n",
    "all_edges = all_edges.merge(activities, left_on='Label', right_on='PMID', how='left')\n",
    "all_edges.to_csv('../data/all_edges.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = all_pub[all_pub['PMID'] == 15057822.0]['AUTHOR_LIST'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "al = a.split(';')\n",
    "print(len(al))\n",
    "from scipy.misc import comb\n",
    "from scipy.special import perm\n",
    "comb(231,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using both publication and author as nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_net.columns = ['Source', 'Target']\n",
    "df_net['Type'] = 'Undirected'\n",
    "df_net.to_csv('../data/edge_pubnode_autnode.csv', index=False, header=True)\n",
    "df_pub = pd.DataFrame({'Id': df_net.Target.unique()})\n",
    "df_pub['Group'] = 'pub'\n",
    "df_nodes = pd.concat([df_group, df_pub], axis=0)\n",
    "df_nodes.to_csv('../data/node_pubnode_autnode.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculate Statstics among author groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-faeccfcc5c1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/nodes_gephi.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "all_nodes = pd.read_csv('../data/nodes_gephi.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_nodes = all_nodes.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes[all_nodes.Group == 'study'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['others', 'study', 'comp'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes.Group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139651, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = Graph(len(all_nodes))\n",
    "g.vs['name'] = all_nodes.Id\n",
    "g.vs['group'] = all_nodes.Group\n",
    "edges = pd.read_csv('../data/edges_gephi.csv', header=0)\n",
    "g.add_edges(edges[['Source', 'Target']].values.tolist())\n",
    "g.es['pmid'] = edges['Label']\n",
    "g.es['PUB_YEAR'] = edges['PUB_YEAR']\n",
    "g.es['COUNTRY'] = edges['COUNTRY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g.vs[\"bs\"] = g.betweenness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average degree of the whole network: 37.73\n",
      "\n",
      "The average degree of the study nodes: 310.85\n",
      "\n",
      "The average degree of the comparison nodes: 530.35\n",
      "\n",
      "The average degree of the other nodes: 35.74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#average degree \n",
    "print('The average degree of the whole network: {0:0.2f}\\n'.format(mean(g.degree())))\n",
    "#study group degree\n",
    "study_nodes = g.vs.select(lambda v : v['group'] == 'study')\n",
    "print('The average degree of the study nodes: {0:0.2f}\\n'.format(mean(study_nodes.degree())))\n",
    "comp_nodes = g.vs.select(lambda v : v['group'] == 'comp')\n",
    "print('The average degree of the comparison nodes: {0:0.2f}\\n'.format(mean(comp_nodes.degree())))\n",
    "other_nodes = g.vs.select(lambda v : v['group'] == 'others')\n",
    "print('The average degree of the other nodes: {0:0.2f}\\n'.format(mean(other_nodes.degree())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nodes with degree 0\n",
    "nodes_no_edges = g.vs.select(_degree=0)\n",
    "len(nodes_no_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average betweenness of the whole network: 232397.24\n",
      "\n",
      "The average betweenness of the study nodes: 12948939.37\n",
      "\n",
      "The average betweenness of the comparison nodes: 21887753.12\n",
      "\n",
      "The average betweenness of the other nodes: 143088.63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#average degree \n",
    "print('The average betweenness of the whole network: {0:0.2f}\\n'.format(mean(g.vs['bs'])))\n",
    "#study group degree\n",
    "study_nodes = g.vs.select(lambda v : v['group'] == 'study')\n",
    "print('The average betweenness of the study nodes: {0:0.2f}\\n'.format(mean(study_nodes['bs'])))\n",
    "comp_nodes = g.vs.select(lambda v : v['group'] == 'comp')\n",
    "print('The average betweenness of the comparison nodes: {0:0.2f}\\n'.format(mean(comp_nodes['bs'])))\n",
    "other_nodes = g.vs.select(lambda v : v['group'] == 'others')\n",
    "print('The average betweenness of the other nodes: {0:0.2f}\\n'.format(mean(other_nodes['bs'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g.vs['closeness'] = g.closeness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average closeness of the whole network: 0.01\n",
      "\n",
      "The average closeness of the study nodes: 0.01\n",
      "\n",
      "The average closeness of the comparison nodes: 0.01\n",
      "\n",
      "The average closeness of the other nodes: 0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#average degree \n",
    "print('The average closeness of the whole network: {0:0.2f}\\n'.format(mean(g.vs['closeness'])))\n",
    "#study group degree\n",
    "study_nodes = g.vs.select(lambda v : v['group'] == 'study')\n",
    "print('The average closeness of the study nodes: {0:0.2f}\\n'.format(mean(study_nodes['closeness'])))\n",
    "comp_nodes = g.vs.select(lambda v : v['group'] == 'comp')\n",
    "print('The average closeness of the comparison nodes: {0:0.2f}\\n'.format(mean(comp_nodes['closeness'])))\n",
    "other_nodes = g.vs.select(lambda v : v['group'] == 'others')\n",
    "print('The average closeness of the other nodes: {0:0.2f}\\n'.format(mean(other_nodes['closeness'])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g.write_pickle('all_author_graph.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have 'read' and 'readline' attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-776a77f4296d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all_author_graph.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: file must have 'read' and 'readline' attributes"
     ]
    }
   ],
   "source": [
    "\n",
    "g = pk.load('all_author_graph.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb\r\n",
      "all_author_graph\r\n",
      "data_exploration_only_fiscal_year_filter_by_cost.ipynb\r\n",
      "data_preparation.ipynb\r\n",
      "edges_gephi.csv\r\n",
      "edges_pmids.csv\r\n",
      "edges_raw.csv\r\n",
      "net_raw.csv\r\n",
      "network_analysis.ipynb\r\n",
      "nih_analyses.db\r\n",
      "sample_questions_v5.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "am = g.get_adjacency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
